{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-us_census_project-vcpu-2-ram-16gib",
      "display_name": "Python in vCPU-2-RAM-16GiB (env us_census_project)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "tags": [
      "recipe-editor"
    ],
    "createdOn": 1762039630760,
    "associatedRecipe": "2-Modeling-recipe",
    "creator": "daniel.t.soukup@gmail.com",
    "customFields": {},
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "daniel.t.soukup@gmail.com"
      },
      "lastModifiedOn": 1762039630760
    },
    "modifiedBy": "daniel.t.soukup@gmail.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling and Fine Tuning\n\n\u003e Owner: Daniel Soukup - Created: 2025.11.01\n\nIn this notebook, we load the processed data and fit our models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s load our processed data and create feature/target dataframes for both train and test."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\nprocessed_learn \u003d dataiku.Dataset(\"processed_learn\")\nprocessed_learn_df \u003d processed_learn.get_dataframe()\n\nprocessed_test \u003d dataiku.Dataset(\"processed_test\")\nprocessed_test_df \u003d processed_test.get_dataframe()\n\nprocessed_learn_df.shape, processed_test_df.shape"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "processed_learn_df.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TARGET \u003d \u0027income\u0027"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, y_train \u003d processed_learn_df.drop(columns\u003dTARGET), processed_learn_df[TARGET]\nX_test, y_test \u003d processed_test_df.drop(columns\u003dTARGET), processed_test_df[TARGET]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall that 8% of the processed samples fall into the target class 1 (high income) so a dummy classifier predicting 0 only would be 92% accurate."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train.mean()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Important Note:** We won\u0027t use the test set for any optimization to avoid overfitting, we reserve the test set for final evaluation only of the optimized model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling\n\nOur current approach will focus on optimizin an XGBoost binary classifier. We do this using Optuna to search the hyperparameter space efficiently. We also aim to address the class imbalance during the training by:\n- using stratified splitting for cross-validation\n- adjusting the evaluation metric from accuracy to AUC (still sensitive but less so than accuracy)\n- experimenting with class-balancing methods, such as class weights and upsampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Baseline"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import Dict, Any\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\ndef cross_val_score_xgb(param: Dict[str, Any]) -\u003e float:\n    \"\"\"\n    Fit model with cross validation using the provided params.\n\n    Return the avg out-of-fold accuracy.\n    \"\"\"\n    dtrain \u003d xgb.DMatrix(X_train, label\u003dy_train)\n\n    results \u003d xgb.cv(\n        params\u003dparam,\n        dtrain\u003ddtrain,\n        num_boost_round\u003dparam.get(\"n_estimators\"), # default 10\n        nfold\u003d3,\n        seed\u003d42,\n        verbose_eval\u003dFalse,\n        stratified\u003dparam.get(\"stratified_cv\"), # default False\n    )\n\n    return results\n\n# we wont change these\nBASE_PARAMS \u003d {\n    \"verbosity\": 0,\n    \"objective\": \"binary:logistic\",\n    \"eval_metric\": \"auc\",\n    \"stratified_cv\": True\n}\n\nparam \u003d BASE_PARAMS.copy()\nparam.update({\n    \"n_estimators\": 10,\n    \"max_depth\": 2,\n    }\n)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results \u003d cross_val_score_xgb(param)\nresults.tail(3)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimize Hyperparameters\n\nNext, we\u0027ll look to optimize the model hyperparameters. As we do this, our experiments will be tracked using MLflow."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n\nproject \u003d dataiku.api_client().get_default_project()\nmanaged_folder \u003d project.get_managed_folder(\u0027lV6oqreY\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def objective(trial):\n    \"\"\"\n    Capture a single param combination and model fitting,\n    evaluated using cross-validation.\n    \"\"\"\n    param \u003d BASE_PARAMS.copy()\n    param.update({\n        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0), # default 1 - all rows\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0), # default 1 - all columns\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100, step\u003d10), # default 100\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20, step\u003d2) # default 3\n    })\n    \n    with mlflow_handle.start_run(run_name\u003d\"trial\", nested\u003dTrue):\n        result \u003d cross_val_score_xgb(param)\n        best_score \u003d result[\"test-auc-mean\"].values[-1]\n        \n        # logging\n        mlflow_handle.log_params(param)\n        mlflow_handle.log_metrics(\n            {\n                \u0027best_score\u0027: best_score\n            }\n        )\n        \n        return best_score"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "import optuna\n\nN_TRIALS \u003d 20\n\nwith project.setup_mlflow(managed_folder\u003dmanaged_folder) as mlflow_handle:\n    \n    mlflow_handle.set_experiment(\"xgboost_hp_tuning\")\n     \n    with mlflow_handle.start_run(run_name\u003d\"study\", nested\u003dTrue) as study_run:\n        study \u003d optuna.create_study(direction\u003d\"maximize\")\n        study.optimize(objective, n_trials\u003dN_TRIALS, timeout\u003d600)\n        \n        # logging\n        best_params \u003d study.best_trial.params\n        mlflow_handle.log_params(best_params)\n        mlflow_handle.log_metrics(\n            {\n                \u0027best_score\u0027: study.best_trial.value\n            }\n        )\n        \n        # refit best model\n        print(\"Fitting best model...\")\n        model \u003d XGBClassifier(**study.best_trial.params)\n        model \u003d model.fit(X_train, y_train)\n        \n        # logging - disabled\n#         mlflow_handle.xgboost.log_model(model)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets see the best results:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Best trial:\")\ntrial \u003d study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tuning Analysis\n\nLet\u0027s see how the HP choices impacted performance:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "study_df \u003d study.trials_dataframe()\nstudy_df.head()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will look at different projections of the HP space and the best observed values:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n\npivot \u003d pd.pivot_table(study_df, index\u003d\"params_max_depth\", columns\u003d\"params_n_estimators\", values\u003d\"value\", aggfunc\u003d\u0027max\u0027)\nfig \u003d px.imshow(\n    pivot,\n    color_continuous_scale\u003d\"blues\",\n    title\u003d\"Best values across combinations\"\n)\nfig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best performing models were found with the higher range of boosting rounds and lower max depth (the latter help avoid overfitting if the the number of estimators is high)."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pivot \u003d pd.pivot_table(study_df, index\u003d\"params_max_depth\", columns\u003d\"params_colsample_bytree\", values\u003d\"value\", aggfunc\u003d\u0027max\u0027)\nfig \u003d px.imshow(\n    pivot,\n    color_continuous_scale\u003d\"blues\",\n    title\u003d\"Best values across combinations\",\n\n)\nfig.update_xaxes(\n    scaleanchor\u003d\"x\",\n  )\nfig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our experiemnts, the high scores also corresponded with smaller col samples (how many col\u0027s each estimater used) and lower max depth. The small col sample again helps avoid overfitting."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pivot \u003d pd.pivot_table(study_df, index\u003d\"params_n_estimators\", columns\u003d\"params_colsample_bytree\", values\u003d\"value\", aggfunc\u003d\u0027max\u0027)\nfig \u003d px.imshow(\n    pivot,\n    color_continuous_scale\u003d\"blues\",\n    title\u003d\"Best values across combinations\",\n\n)\nfig.update_xaxes(\n    scaleanchor\u003d\"x\",\n  )\nfig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is confirmed here again: the combination of low col sample rate and low max depth allows us to train longer and get better results. Given that the best results were observed at the end of the specified search range, it would be a good next step to extend the range further, potentially with a larger stepsize for boosting rounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict\n\nWe save the predicted class and probabilities both calculated:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions_learn_df \u003d pd.DataFrame(\n    {\n        TARGET: y_train,\n        \u0027pred\u0027: model.predict(X_train),\n        \u0027pred_proba\u0027: model.predict_proba(X_train)[:, 1]\n    }\n)\n\npredictions_test_df \u003d pd.DataFrame(\n    {\n        TARGET: y_test,\n        \u0027pred\u0027: model.predict(X_test),\n        \u0027pred_proba\u0027: model.predict_proba(X_test)[:, 1]\n    }\n)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save predictions\n\nWe finally save the results to their own datasets which can be used for evaluation:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\npredictions_learn \u003d dataiku.Dataset(\"predictions_learn\")\npredictions_learn.write_with_schema(predictions_learn_df)\n\npredictions_test \u003d dataiku.Dataset(\"predictions_test\")\npredictions_test.write_with_schema(predictions_test_df)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "study_data \u003d dataiku.Dataset(\"xgboost_study\")\nstudy_data.write_with_schema(study_df)"
      ],
      "outputs": []
    }
  ]
}
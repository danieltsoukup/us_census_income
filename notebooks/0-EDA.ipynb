{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-us_census_project-vcpu-2-ram-16gib",
      "display_name": "Python in vCPU-2-RAM-16GiB (env us_census_project)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "daniel.t.soukup@gmail.com",
    "createdOn": 1762010444954,
    "creator": "daniel.t.soukup@gmail.com",
    "tags": [],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis\n\n**Owner: Daniel Soukup - Created: 2025.11.01**\n\nThe goal of this notebook is to explore the dataset, understand our target column and features (statistical properties, data quality) and plan for preprocessing and modelling."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport numpy as np\n\nimport plotly.express as px\n\nimport plotly.offline as pyo\npyo.init_notebook_mode()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n\nLet\u0027s ensure the datasets are available:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nproject \u003d client.get_project(\u0027US_CENSUS_PROJECT\u0027)\n\ndatasets \u003d project.list_datasets()\n\nfor dataset in datasets:\n    print(dataset[\"name\"])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the datasets:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_data_by_name(name: str) -\u003e pd.DataFrame:\n    \"\"\"\n    Load dataset by its name.\n    \"\"\"\n    mydataset \u003d dataiku.Dataset(name)\n    mydataset_df \u003d mydataset.get_dataframe()\n    \n    return mydataset_df\n\ntrain_df \u003d load_data_by_name(\"census_income_learn\")\ntest_df \u003d load_data_by_name(\"census_income_test\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have ~200K rows for testing and ~100K rows for testing with 42 columns, the last being our target. Note that we are missing the column names."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_df.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.info()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations:**\n\nIt is clear that we need to do a fair bit of cleaning:\n- clarify the missing column names by matching the fields to the provided data dictionary\n- there are some missing values in col11 that need to be investigated and addressed\n- we have a high number of object data types that will need processing prior to modeling\n\nExcerpt from the data dict:\n\n- Number of instances data \u003d 199523\n    - Duplicate or conflicting instances : 46716\n- Number of instances in test \u003d 99762\n    - Duplicate or conflicting instances : 20936\n- Class probabilities for income-projected.test file\n    - Probability for the label \u0027- 50000\u0027 : 93.80%\n    - Probability for the label \u002750000+\u0027 : 6.20%\n- Number of attributes \u003d 40 (continuous : 7 nominal : 33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick check confirms that there are no exact duplicate columns per se:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# note: runs long\ntrain_df.T.duplicated().sum()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Column Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets look at the high level stats first:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# numeric columns\ntrain_df.describe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# categorical\ntrain_df.select_dtypes(\"object\").describe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We\u0027ll use the data dictionary and number of unique values to map our columns to their proper names. We also need this information to make well-informed decisions on how the columns should be processed for modelling."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "pd.set_option(\u0027display.max_colwidth\u0027, 100) \n\nunique_values \u003d pd.DataFrame(\n    {\n        \"unique_values\": [train_df[col].unique() for col in train_df.columns],\n        \"num_unique\": [train_df[col].nunique() for col in train_df.columns],\n        \"dtype\": [train_df[col].dtype for col in train_df.columns],\n    },\n    index\u003dtrain_df.columns,\n)\nunique_values"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on this we put together our mapping:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "col_mapping \u003d {\n    \"col_0\": \"age\", # matches type and range\n    \"col_1\": \"class of worker\", # unique values checked with data dict (UVDD)\n    \"col_2\": \"detailed industry recode\", # UVDD\n    \"col_3\": \"detailed occupation recode\", # UVDD\n    \"col_4\": \"education\", # UVDD\n    \"col_5\": \"wage per hour\", # looks to be at right position, type checks, in cents?\n    \"col_6\": \"enroll in edu inst last wk\", # UVDD\n    \"col_7\": \"marital stat\", # UVDD\n    \"col_8\": \"major industry code\", # UVDD\n    \"col_9\": \"major occupation code\", # UVDD\n    \"col_10\": \"race\", # UVDD\n    \"col_11\": \"hispanic origin\", # UVDD - 10 unique in data dict? values match though\n    \"col_12\": \"sex\", # UVDD\n    \"col_13\": \"member of a labor union\", # UVDD\n    \"col_14\": \"reason for unemployment\", # UVDD\n    \"col_15\": \"full or part time employment stat\", # UVDD\n    \"col_16\": \"capital gains\", # data dict check, range ok, dollars?\n    \"col_17\": \"capital losses\", # data dict check, range ok, dollars?\n    \"col_18\": \"dividends from stocks\", # data dict check\n    \"col_19\": \"tax filer stat\", # UVDD\n    \"col_20\": \"region of previous residence\", # UVDD\n    \"col_21\": \"state of previous residence\", # UVDD\n    \"col_22\": \"detailed household and family stat\", # data dict check\n    \"col_23\": \"detailed household summary in household\", # data dict check\n    \"col_24\": \"instance weight\", # SPECIAL\n    \"col_25\": \"migration code-change in msa\", # UVDD\n    \"col_26\": \"migration code-change in reg\", # UVDD\n    \"col_27\": \"migration code-move within reg\", # UVDD\n    \"col_28\": \"live in this house 1 year ago\",# UVDD\n    \"col_29\": \"migration prev res in sunbelt\", # UVDD\n    \"col_30\": \"num persons worked for employer\", # value check\n    \"col_31\": \"family members under 18\", # UVDD\n    \"col_32\": \"country of birth mother\",  # UVDD\n    \"col_33\": \"country of birth self\",  # UVDD\n    \"col_34\": \"country of birth father\",  # UVDD\n    \"col_35\": \"citizenship\", # UVDD\n    \"col_36\": \"own business or self employed\", # UVDD\n    \"col_37\": \"fill inc questionnaire for veteran\u0027s admin\", # UVDD\n    \"col_38\": \"veterans benefits\", # UVDD\n    \"col_39\": \"weeks worked in year\", # data dict order\n    \"col_40\": \"year\", # UVDD\n    \"col_41\": \"income\"\n}"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "About the instance weight:\n\n\u003e The instance weight indicates the number of people in the population\n that each record represents due to stratified sampling.\n To do real analysis and derive conclusions, this field must be used.\n This attribute should *not* be used in the classifiers, so it is\n set to \"ignore\" in this file.\n \n \nMore info from [census.gov](https://www.census.gov/programs-surveys/cps/technical-documentation/methodology/weighting.html):\n\n\u003eThe base weight, which is the inverse of the probability of the person being in the sample, is a rough measure of the number of actual persons that the sample person represents. Almost all sample persons in the same state have the same base weight, but the weights across states are different. Selection probabilities may also differ for some sample areas due to field subsampling, which is done when areas selected for the sample contain many more households than expected. The base weights are then adjusted for noninterview, and the ratio estimation procedure is applied.\n\nWe won\u0027t be using this field for modeling as per the data dictionary recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to map the names:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df \u003d train_df.rename(columns\u003dcol_mapping)\ntest_df \u003d test_df.rename(columns\u003dcol_mapping)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.head()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Univariate distributions\n\nWe look at the univariate distribution of each column that will help us deciding on any preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numerical Fields\n\nFirst, look at the numeric fields:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.select_dtypes([\u0027int\u0027, \u0027float\u0027])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By a quick glance, we can recognize that some of these columns are codes actually hence better dealt with as categories:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_only_df \u003d train_df.select_dtypes([\"int\", \"float\"])\n\nunique_values \u003d pd.DataFrame(\n    {\n        \"num_unique\": [num_only_df[col].nunique() for col in num_only_df.columns],\n        \"dtype\": [num_only_df[col].dtype for col in num_only_df.columns],\n    },\n    index\u003dnum_only_df.columns,\n)\nunique_values"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The numbers encode independent values with no numeric relationship: veterans benefits, own business, and the two the recodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One might consider adding \"num persons worked for employer\" and \"year\" as well, given the concentration to only a few unique values."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df[\"num persons worked for employer\"].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df[\"year\"].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s convert these and process with the rest of the categorical columns:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_to_object_cols \u003d [\n    \"detailed industry recode\", \n    \"detailed occupation recode\",\n    \"own business or self employed\",\n    \"veterans benefits\",\n    \"year\",\n    \"num persons worked for employer\",\n]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for col in num_to_object_cols:\n    train_df[col] \u003d train_df[col].astype(\"object\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at high level stats:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_cols \u003d train_df.select_dtypes(\u0027number\u0027)\nnum_cols.describe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see some major skew in these fields and some curious values, such as the 9999 and 99999 for the dollar values. "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "def plot_numeric(column: str) -\u003e None:\n    fig \u003d px.histogram(train_df, x\u003dcolumn, title\u003df\"{column} distribution\")\n    fig.show()\n    \nfor col in num_cols.columns:\n    plot_numeric(col)\n    \n    "
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations:\n- weeks worked is mostly 0 or 52\n- most distributions highly skewed to the right with a few large outliers (wage per hour, cap loss/gain, dividend, instance weight)\n- age distribution is interestingly bimodal with moderate right skew\n\nIt is likely that either 9999 was used as a filler value in these columns or used as an artificial maximum to protect the privacy of some outlier data subjects."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(train_df[\u0027wage per hour\u0027] \u003d\u003d 9999).sum()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(train_df[\u0027capital gains\u0027] \u003d\u003d 99999).sum()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(train_df[\u0027dividends from stocks\u0027] \u003d\u003d 99999).sum()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are extreme outlier values of the fields (based on the percentiles above). We also saw that there are a really high % of values falling exactly at 0:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "for col in num_cols.columns:\n    fig \u003d px.histogram(train_df.loc[train_df[col] \u003e 0], x\u003dcol)\n    fig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows us to see the distribution better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Proposal**\n- we will focus on tree-based algorithms for modelling which are quite robust to outliers and scale differences so for now we\u0027ll leave the columns as is during preprocessing\n\nIn the future, we can apply log-transformation, scaling to these fields if the models require. We can alternatively consider binning to create categorical fields from these variables too (based on uniform or percentile bins)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical fields\n\nLets consider now the categorical fields."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pyo.init_notebook_mode()\n\nTARGET \u003d \u0027income\u0027\n\n\ndef plot_categories(column: str) -\u003e None:\n    \"\"\"\n    Plot top-20 value counts.\n    \"\"\"\n    counts \u003d train_df[column].value_counts(normalize\u003dTrue).head(20)\n    fig \u003d px.bar(counts, title\u003df\"{column} distribution\")\n    fig.show()\n    \nplot_categories(TARGET)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a highly imbalance distribution, with only 6% of train samples in the +50K category. This will likely need addressing, the classification models will be affected and in general, we expect worse performance on this minority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets see the rest of the columns:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pyo.init_notebook_mode()\n\nfor col in train_df.select_dtypes(\"object\"):\n    plot_categories(col)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see most columns are again imbalanced with a high number of unique values and long tails."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.select_dtypes(\"object\").nunique()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If all columns are dummy encoded we get \u003e 450 cols (once one of each category dropped):"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.select_dtypes(\"object\").nunique().sum() - train_df.shape[1]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In terms of encoding and processing:\n- we would typically create one-hot vectors from the categories to be used with modelling\n- to avoid extremely high dim data, we should roll up categories before dummy encoding\n    - this can be done based on our insight of related categories,\n    - or using automated feature selection after getting each dummy column\n- some categories (education) show clear order which we expect also to have a natural correlation with the target (higher education -\u003e higher income) - it would be an option to encode along a rank, say 1 to 5 the level of education."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Proposal**:\n- as our initial approach, we shall dummy encode the categorical fields\n- use category frequency thresholds to decide on if that value deserves it\u0027s own field\n- limit the max number of categories introduced\n\nOur preprocessing pipeline will implement these steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Values "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see there is only a single column with missing values, for \u003c0.5% of the rows:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.isna().mean()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.isna().sum().sum()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the data glossary provided:\n\n\u003eHispanic Origin\nPersons of Hispanic origin in this file are determined on\nthe basis of a question asking if the person is Spanish,\nHispanic, or Latino. If the response is “yes,” a follow-up\nquestion determines a specific ethnic origin, asking to\nselect their (the person’s) origin from a “flash card”\nlisting. The flash-card selections are Mexican, Mexican-\nAmerican, Chicano, Puerto Rican, Cuban, Cuban\nAmerican, or some other Spanish, Hispanic, or Latino\ngroup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If these values are missing at random, dropping them likely makes little difference to the modelling."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.loc[train_df.isnull().any(axis\u003d1), \"race\"].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df[\u0027race\u0027].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df[\u0027hispanic origin\u0027].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.loc[train_df.isnull().any(axis\u003d1), \"income\"].value_counts(normalize\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rows do not seem to be skewed with respect to our target or the \u0027race\u0027 column. However, in general we try to avoid dropping rows at all costs to avoid biasing the data inadvertently.\n\n**Proposal**: Since the `hispanic origin` column already has a `Do not know` value, we can fill with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplicate Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets see how many duplicate rows we have:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.duplicated().sum()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is already significant, but if we look at without our instance weight column:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.drop(columns\u003d[\u0027instance weight\u0027, \u0027income\u0027]).duplicated().sum()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that without our weight and income column, we get the exact number of duplicate instances mentioned in the data dictionary.\n\n\u003e Number of instances data \u003d 199523\n    Duplicate or conflicting instances : 46716\n Number of instances in test \u003d 99762\n    Duplicate or conflicting instances : 20936"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is unclear where these are coming from and there is no ID to identify data subjects (as per the anonymization). Note that this is a significant number of rows to drop from our data and it could be that some of these duplicates are legitimate (two people with the same recorded attributes)."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "without_duplicates \u003d train_df.drop_duplicates(subset\u003dtrain_df.drop(columns\u003d[\u0027instance weight\u0027, \u0027income\u0027]).columns)\nwithout_duplicates.shape"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: the Census does put a fair effort into deduplication. https://www.census.gov/newsroom/blogs/random-samplings/2021/04/how_we_unduplicated.html\n\n\u003eThere are several reasons for duplicates in a census:\n    We receive more than one response for an address.\n    People are counted in more than one place because of potentially complex living situations.\n    There might be an issue with the address — a housing unit is on our address list more than once or census materials are misdelivered.\n    We use a special algorithm to resolve the first situation and a series of steps to resolve the second and third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Proposal**: we will drop these rows since there is no additional evidence that these are not corrupted (see data dict). \n\nFor our tree learning algorithm, having duplicate rows would amount to weighting the data points which is really done through the instance weight column already, which we decided not to use for modelling. In real business situations, we\u0027d explore the reason for duplication and make the best decision based on more in-depth understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relationship to Target\n\nWe\u0027d like to get a sense which columns are most strongly related to the target. We can do this by standard statistics and tests (chi2 or f-score). We leave the feature selection to the preprocessing notebook and explore select columns here that are promising predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only weak relationship between the numeric features."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig \u003d px.imshow(\n    train_df.select_dtypes(\u0027number\u0027).corr(),\n    text_auto\u003dTrue,\n    color_continuous_scale\u003d\u0027RdBu_r\u0027,\n    zmin\u003d-1,\n    zmax\u003d1\n)\nfig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Between our target and the numeric features:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pyo.init_notebook_mode()\n\nfor col in train_df.select_dtypes(\u0027number\u0027):\n    fig \u003d px.box(train_df, x\u003dcol, color\u003d\"income\")\n    fig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After a bit of transformations, we can get a better visual:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pyo.init_notebook_mode()\n\nfor col in train_df.select_dtypes(\u0027number\u0027):\n    filtered \u003d train_df[train_df[col] \u003e 0] # Note there are lot of data points filtered\n    filtered[col] \u003d np.log1p(filtered[col])\n    fig \u003d px.box(filtered, x\u003dcol, color\u003d\"income\")\n    fig.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations:\n- large earners are older on average\n- we can see some expected relationship with wage and gains/losses as well as weeks worked\n\nWe could use a two-sample t-test for checking statistical significance of the difference in distributions (although need to be careful with the large sample size)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, looking at our categorical fields, we can check pivot tables and chi2 scores, selecting the most significant results by a 0.001 p-value threshold to account for multiple testing:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.stats import chi2_contingency\n\n# run on a sample, chi2 will give more false pos with super large samples\nsample \u003d train_df.sample(1000)\n\nresults \u003d []\nfor col in train_df.select_dtypes(\u0027object\u0027).drop(columns\u003dTARGET):\n    contingency_table \u003d sample.groupby([col, TARGET])[TARGET].count().unstack().fillna(0)\n    chi2_stat, p_value, dof, expected \u003d chi2_contingency(contingency_table)\n    results.append(\n        {\n            \u0027col\u0027: col,\n            \u0027chi2\u0027: chi2_stat,\n            \u0027p_value\u0027: p_value,\n        }\n    )\n    \nchi2_results \u003d pd.DataFrame(results)\n\n# significant with 0.1% cutoff to account for multiple testing\nchi2_results[chi2_results[\"p_value\"] \u003c 0.001]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that these are reasonable columns, industry, class of worker, employment status, etc are highly likely to affect the income. We expect these to show up in our modelling as well and help guide prioritizing feature selection."
      ]
    }
  ]
}